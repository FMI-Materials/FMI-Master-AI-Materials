{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Segmentation\n",
    "Image segmentation is a fundamental problem in computer vision where the goal is to group pixels with similar characteristics such as color, intensity, texture, semantic class. The result of image segmentation is a set of segments that collectively cover the entire image. Pixels grouped in the same segments are similar with respect to some characteristic. Adjacent regions are significantly different with respect to the same characteristic. \n",
    "\n",
    "In this exercise class we will focus on the problem of image segmentation using low-level features like texture and color. The goal is to produce a set of segments where pixels grouped in the same segment have similar texture or color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this before starting the lab\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import glob\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "import scipy.io\n",
    "from skimage.segmentation import slic\n",
    "from skimage.segmentation import mark_boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are going to use this to save all the segmentation obtained in this lab to display them at the end\n",
    "history_segmentation = {}\n",
    "def save_history(image_path, segmentation, method_name):\n",
    "    if image_path not in history_segmentation: \n",
    "        history_segmentation[image_path] = {}\n",
    "    history_segmentation[image_path][method_name] = segmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_filters(filters, num_rows, num_cols, theta_list=None, lambda_list=None):\n",
    "    \"\"\"\n",
    "    Visualize the filters.\n",
    "    :param num_rows. How many rows are used to display the filters.\n",
    "    :param num_cols. How many columns are used to display the filters. \n",
    "    :param filters. Filters with the shape N x K x K.\n",
    "    :param theta_list. The list with the theta parameters.\n",
    "    :param lambda_list. The list with the lambda paramters.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 15)) \n",
    " \n",
    "    for i in range(num_rows):\n",
    "        for j in range(num_cols):\n",
    "            if i * num_cols + j < len(filters):\n",
    "                plt.subplot(num_rows, num_cols, i * num_cols + j + 1)\n",
    "                plt.axis('off')                  \n",
    "                plt.imshow(filters[i * num_cols + j], extent=[0, 100, 0, 1], aspect=100)\n",
    "                if theta_list is not None:\n",
    "                    plt.title(\"L = %s T= %.2f\" % (lambda_list[i], theta_list[j]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(image_1, image_2=None, image_3=None, name_1='image_1', name_2='image_2', name_3='image_3', time_out=0):\n",
    "    \"\"\"\n",
    "    Show images received as parameters.\n",
    "    \"\"\"\n",
    "    cv.imshow(name_1, image_1)\n",
    "    if image_2 is not None:\n",
    "        cv.imshow(name_2, image_2)\n",
    "    if image_3 is not None:\n",
    "        cv.imshow(name_3, image_3)\n",
    "    cv.waitKey(time_out)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_DIFFERENT_COLORS = 50\n",
    "random_colors = np.uint8(np.random.randint(255, size=(NUMBER_DIFFERENT_COLORS, 3)))\n",
    "\n",
    "def label_to_rgb(img_label, colors=random_colors):\n",
    "    \"\"\"\n",
    "    It colors the image based on the label number.\n",
    "    :param img_label. The 'image' containing a label for each patch/portion of the image.\n",
    "    :param colors\n",
    "    :return the colored image.\n",
    "    \"\"\"\n",
    "    h, w = img_label.shape\n",
    "    fake_colored_label_image = np.uint8(np.zeros((h, w, 3))) \n",
    "    \n",
    "    number_labels = img_label.max() + 1\n",
    "    number_different_colors = colors.shape[0] \n",
    "    \n",
    "    for label in range(number_labels):\n",
    "        rows, columns = np.where(img_label == label)\n",
    "        fake_colored_label_image[rows, columns, :] = colors[label % number_different_colors]\n",
    "    return fake_colored_label_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_kmeans(features, num_clusters):\n",
    "    \"\"\"\n",
    "    Return the model after performing the Kmeans algorithm.\n",
    "    :param features\n",
    "    :param num_clusters.\n",
    "    :return kmeans model.\n",
    "    \"\"\"\n",
    "    kmeans_model = KMeans(init=\"random\", n_clusters=num_clusters, n_init=10, max_iter=300, random_state=42)\n",
    "    begin = time.time() \n",
    "    kmeans_model.fit(np.float32(features))\n",
    "    end = time.time() \n",
    "    print(f\"Kmeans clustering took {end-begin} seconds\")\n",
    "    return kmeans_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gabor_filters(theta_list, lambda_list) -> list:\n",
    "    # useful links for gabor filters\n",
    "    # build Gabor filters for texture \n",
    "    # see the gif Gabor_filter_values_visualization.gif \n",
    "    # https://medium.com/@anuj_shah/through-the-eyes-of-gabor-filter-17d1fdb3ac97\n",
    "    # https://stackoverflow.com/questions/30071474/opencv-getgaborkernel-parameters-for-filter-bank\n",
    "    \"\"\"\n",
    "    We build Gabor filters with the window size of 31 pixels and theta and lambda received in the paramters.\n",
    "    :param theta_list. The list with the theta parameters.\n",
    "    :param lambda_list. The list the lambda paramters.\n",
    "    :return. list of Gabor filters.\n",
    "    \"\"\"\n",
    "    filters = []\n",
    "    ksize = 31\n",
    "    \n",
    "    for lambda_ in lambda_list:   \n",
    "        for theta in theta_list:    \n",
    "            kern = cv.getGaborKernel((ksize, ksize), 4, theta, lambda_, 0.5, 0, ktype=cv.CV_32F)\n",
    "            kern /= 1.5 * kern.sum()\n",
    "            filters.append(kern)            \n",
    "    return filters\n",
    "\n",
    "\n",
    "def apply_filters(img, filters: list):\n",
    "    \"\"\"\n",
    "    :param img - the image on which we apply the filters.\n",
    "    :param filter - a list with filters.\n",
    "    :return. The results of applying the filters on the image.\n",
    "    \"\"\"\n",
    "    img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    h, w = img_gray.shape\n",
    "    \n",
    "    number_filters = len(filters)\n",
    "    responses = np.zeros((h, w, number_filters))\n",
    "    for idx, kernel in enumerate(filters):        \n",
    "        responses[:, :, idx] = np.abs(cv.filter2D(img_gray, cv.CV_32F, kernel))        \n",
    "    return responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pixel level segmentation\n",
    "## Pixel level segmentation - texture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Visualize the Gabor filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We build Gabor filters with the window size of 31 pixels and theta between 0 and PI (with a step of 45 degrees)\n",
    "# and lambda between 10 and 80 (inclusive) with a step of 20.\n",
    "theta_list = np.arange(0, np.pi, np.pi / 4)\n",
    "lambda_list = np.arange(10, 90, 20)\n",
    "gabor_filters = build_gabor_filters(theta_list=theta_list, lambda_list=lambda_list)\n",
    "visualize_filters(gabor_filters, num_rows=len(lambda_list), num_cols=len(theta_list),\n",
    "                        theta_list=theta_list, lambda_list=lambda_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our first task is to segment the images from the 'dataset' folder using the Gabor / Custom filters response for each pixel as features. \n",
    "In order to complete the task, we have to do:\n",
    "1. Obtain the filters response (our features), for each pixel in our dataset.\n",
    "2. Cluster the resulting features using the K-means algorithm.\n",
    "3. Obtain the segmentation of each image by predicted the cluster assigment of the pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filters_response(image_paths: list, filters):\n",
    "    \"\"\"\n",
    "    Return a matrix of size (number_of_total_pixels X number_of_applied_filters) which is defined\n",
    "    by applying the filters on each pixel in our dataset.\n",
    "    1. For each image from the dataset, apply the filters.\n",
    "    2. Store the result into a matrix of dimension (number_of_total_pixels X number_of_applied_filters).\n",
    "    :param image_paths: The paths of the images in our dataset.\n",
    "    :param filters: The filters used to define each pixel.\n",
    "    :return: Return a matrix of size (number_of_total_pixels X number_of_applied_filters).\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    # TODO: \n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segmentation_based_on_texture(image, filters, kmeans_model):\n",
    "    \"\"\"\n",
    "    1. Apply the filters on the image.\n",
    "    2. Obtain the cluster number of each pixel.\n",
    "    3. Obtain the segmentation by reshaping the kmeans output.\n",
    "    \"\"\"\n",
    "    # TODO: \n",
    "    \n",
    "    segmentation = ...\n",
    "    return segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_images_using_texture_filters(image_paths, filters, num_clusters=5, method_name='gabor_filters'):\n",
    "    \"\"\"\n",
    "    1. Get the filters response for each pixel in our dataset.\n",
    "    2. Cluster the features using the Kmeans algorithm.\n",
    "    3. Get the segmetation of the image using the clusters obtained earlier.\n",
    "    4. Visualize the result (use the show_images function)\n",
    "    \"\"\"\n",
    "    \n",
    "    features = get_filters_response(image_paths, filters)\n",
    "    print(f'Our features size is {features.shape}')\n",
    "    kmeans_model = apply_kmeans(features, num_clusters=num_clusters)\n",
    "    for image_path in image_paths:\n",
    "        img = cv.imread(image_path)\n",
    "        segmentation = get_segmentation_based_on_texture(img, filters, kmeans_model)\n",
    "        colored_segmentation = label_to_rgb(segmentation)\n",
    "        # save the output\n",
    "        save_history(image_path, colored_segmentation, method_name)\n",
    "        show_images(image_1=img, name_1='img', image_2=colored_segmentation, name_2='segmentation')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run segmentation by texture\n",
    "image_paths = glob.glob(\"dataset/*_s.bmp\")\n",
    "segment_images_using_texture_filters(image_paths, gabor_filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, we are going to change the filters and see what segmantion maps we will get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_custom_filters():\n",
    "    \"\"\"\n",
    "    Load filters from Matlab and return the filters as a list.\n",
    "    \"\"\"\n",
    "    mat = scipy.io.loadmat('colectieFiltre.mat') \n",
    "    filters = mat['F']\n",
    "    filters_list = []\n",
    "    for i in range(filters.shape[2]):\n",
    "        filters_list.append(filters[:, :, i].copy())\n",
    "    return filters_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load and visualize the new filters\n",
    "custom_filters = load_custom_filters()\n",
    "visualize_filters(custom_filters, num_rows=7, num_cols=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run segmentation by texture\n",
    "image_paths = glob.glob(\"dataset/*_s.bmp\")\n",
    "segment_images_using_texture_filters(image_paths, custom_filters, method_name='custom_filters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pixel level segmentation - color\n",
    "### Our second task is to segment the images from the 'dataset' folder using the RBG values as features for each pixel. \n",
    "In order to complete the task, we have to do:\n",
    "1. Get the RGB value, for each pixel in our dataset.\n",
    "2. Cluster the resulting features using the K-means algorithm.\n",
    "3. Obtain the segmentation of each image by predicted the cluster assigment of the pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rgb_response(image_paths: list):\n",
    "    \"\"\"\n",
    "    Return a matrix of size (number_of_total_pixels X 3).\n",
    "    1. For each image from the dataset, get the BGR/RGB pixel values.\n",
    "    2. Store the result into a matrix of dimension (number_of_total_pixels X 3).\n",
    "    :param image_paths: The paths of the images in our dataset.\n",
    "    :param filters: The filters used to define each pixel.\n",
    "    :return: Return a matrix of size (number_of_total_pixels X 3).\n",
    "    \"\"\"\n",
    "    features = [] \n",
    "    # TODO:\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segmentation_based_on_color(image, kmeans_model):\n",
    "    \"\"\"\n",
    "    1. Get the RGB for each pixel in the image.\n",
    "    2. Obtain the cluster number of each pixel.\n",
    "    3. Obtain the segmentation by reshaping the kmeans output.\n",
    "    \"\"\" \n",
    "    \n",
    "    # TODO: \n",
    "    segmentation = ...   \n",
    "    return segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_images_based_on_color(image_paths, num_clusters=5, method_name=\"color\"):\n",
    "    \"\"\"\n",
    "    1. Get the RGB for each pixel in our dataset.\n",
    "    2. Cluster the features using the Kmeans algorithm.\n",
    "    3. Get the segmatation of the image using the clusters obtained earlier.\n",
    "    4. Visualize the result (use the show_images function)\n",
    "    \"\"\"\n",
    "    \n",
    "    features = get_rgb_response(image_paths)\n",
    "    print(f'Our features size is {features.shape}')\n",
    "    kmeans_model = apply_kmeans(features, num_clusters=num_clusters)\n",
    "    for image_path in image_paths:\n",
    "        img = cv.imread(image_path)\n",
    "        segmentation = get_segmentation_based_on_color(img, kmeans_model)\n",
    "        colored_segmentation = label_to_rgb(segmentation)\n",
    "        # save the output\n",
    "        save_history(image_path, colored_segmentation, method_name)\n",
    "        show_images(image_1=img, name_1='img', image_2=colored_segmentation, name_2='segmentation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run segmentation by color\n",
    "image_paths = glob.glob(\"dataset/*_s.bmp\")\n",
    "segment_images_based_on_color(image_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Superpixel level segmentation\n",
    "A superpixel can be defined as a group of pixels which have similar characteristics. It is generally color based segmentation. Superpixels can be very helpful for image segmentation: \n",
    "(i)   superpixels reduce the complexity of the images themselves from hundreds of thousands of pixels to only a few hundred superpixels providing thus an efficient representation of images\n",
    "(ii)  pixels that belong to a superpixel group share some sort of commonality, such as similar color or texture distribution.\n",
    "(iii) most superpixel algorithms oversegment the image. This means that most of important boundaries in the image are found; however, at the expense of generating many insignificant boundaries. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We are going to use the SLIC (Simple Linear Iterative Clustering) algorithm from Scikit-image.\n",
    "more details you can find here: https://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.slic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_slic(image, show_images_=False):\n",
    "    \"\"\"\n",
    "    Apply the SLIC algorithm on the image received as paramters.\n",
    "    :param image.\n",
    "    :show_images_. If True the result of the algorithm is shown.\n",
    "    :return The superpixels obtained by running the SLIC algorithm.\n",
    "    \"\"\"\n",
    "    segments_slic = slic(image, n_segments=250, compactness=10, start_label=1)  \n",
    "    if show_images_:\n",
    "        colored_segments = label_to_rgb(segments_slic)\n",
    "        show_images(image_1=image, image_2=colored_segments, name_1='image', name_2='splic_segmentation',\n",
    "                    image_3=mark_boundaries(image, segments_slic), name_3='boundaries')\n",
    "    return segments_slic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see how superpixels works\n",
    "image = cv.imread('dataset/7_25_s.bmp')\n",
    "apply_slic(image, show_images_=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our third task is to segment the images from the 'dataset' folder using the Gabor filters response for each superpixel as features. \n",
    "In order to complete the task, we have to do:\n",
    "1. Get the superpixel for each image.\n",
    "2. For each superpixel, obtain the mean of the filters response (these are the features). \n",
    "2. Cluster the resulting features using the K-means algorithm.\n",
    "3. Obtain the segmentation of each image by predicted the cluster assigment of the pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_response_superpixel_texture(image, segments_slic, filters):\n",
    "    \"\"\"\n",
    "    1. For each superpixel, obtain the mean of the filters response (these are the features).\n",
    "    :param image.\n",
    "    :param segments_slic: The results obtained after running the SLIC algorithm.\n",
    "    :param filters. The filters applied to the pixels.\n",
    "    :return The mean filters response for each superpixels.\n",
    "    \"\"\"\n",
    "    responses = apply_filters(image, filters)\n",
    "    number_superpixels = segments_slic.max()\n",
    "    superpixel_mean_response = np.zeros((number_superpixels, len(filters)))\n",
    "    for label in range(number_superpixels):\n",
    "        rows, columns = np.where(segments_slic == label + 1) # this is because when we called the splic function, we set start_label=1\n",
    "        superpixel_responses = responses[rows, columns, :]\n",
    "        superpixel_mean_response[label] = np.mean(superpixel_responses, axis=0) \n",
    "        \n",
    "    return superpixel_mean_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_superpixel_segmetation_based_on_texture(image, filters, kmeans_model):\n",
    "    \"\"\"\n",
    "    1. For each image, obtain the superpixels. \n",
    "    2. For each superpixel, obtain the mean of the filters response.\n",
    "    3. Cluster the resulting features using the K-means algorithm.\n",
    "    4. Get the segmentation map by labelling each superpixel with the corresponding cluster label.\n",
    "    \"\"\"\n",
    "    segments_slic = apply_slic(image)\n",
    "    superpixel_mean_response = get_mean_response_superpixel_texture(image, segments_slic, filters)\n",
    "    num_superpixel, _ = superpixel_mean_response.shape\n",
    "    predicted_labels = kmeans_model.predict(superpixel_mean_response)\n",
    "    segmentation = np.zeros_like(segments_slic)\n",
    "    for label in range(num_superpixel): \n",
    "        rows, columns = np.where(segments_slic == label + 1)    \n",
    "        segmentation[rows, columns] = predicted_labels[label]\n",
    "    return segmentation\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_images_with_superpixel_based_on_texture(image_paths, filters, num_clusters=5, method_name=\"superpixel_gabor\"):\n",
    "    \"\"\"\n",
    "    1. Get the superpixel for each image.\n",
    "    2. For each superpixel, obtain the mean of the filters response (these are the features). \n",
    "    2. Cluster the resulting features using the K-means algorithm.\n",
    "    3. Obtain the segmentation of each image by predicted the cluster assigment of the pixels.\n",
    "    \"\"\"\n",
    "    def get_superpixels_features(images_paths_, filters_):\n",
    "        features_ = []\n",
    "        num_filters_ = len(filters_)\n",
    "        for image_path in images_paths_:\n",
    "            image = cv.imread(image_path)\n",
    "            segments_slic = apply_slic(image)\n",
    "            superpixel_mean_response = get_mean_response_superpixel_texture(image, segments_slic, filters_)\n",
    "            features_.extend(superpixel_mean_response.reshape(-1, num_filters_))\n",
    "        return np.array(features_)\n",
    "    \n",
    "    features = get_superpixels_features(image_paths, filters)\n",
    "    print(f'Our features size is {features.shape}')\n",
    "    \n",
    "    kmeans_model = apply_kmeans(features, num_clusters=num_clusters)\n",
    "    \n",
    "    for image_path in image_paths:\n",
    "        img = cv.imread(image_path)\n",
    "        segmentation = get_superpixel_segmetation_based_on_texture(img, filters=filters, kmeans_model=kmeans_model)\n",
    "        colored_segmentation = label_to_rgb(segmentation)\n",
    "        # save the output\n",
    "        save_history(image_path, colored_segmentation, method_name)\n",
    "        show_images(image_1=img, name_1='img', image_2=colored_segmentation, name_2='segmentation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run segmentation with superpixels based on texture\n",
    "image_paths = glob.glob(\"dataset/*_s.bmp\")\n",
    "theta_list = np.arange(0, np.pi, np.pi / 4)\n",
    "lambda_list = np.arange(10, 90, 20)\n",
    "gabor_filters = build_gabor_filters(theta_list=theta_list, lambda_list=lambda_list)\n",
    "segment_images_with_superpixel_based_on_texture(image_paths, gabor_filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Superpixel level segmentation - color\n",
    "### Our fourth (and last) task is to segment the images from the 'dataset' folder using the RGB mean values for each superpixel as features. \n",
    "In order to complete the task, we have to do:\n",
    "1. Get the superpixel for each image.\n",
    "2. For each superpixel, obtain the mean rgb value (these are the features). \n",
    "2. Cluster the resulting features using the K-means algorithm.\n",
    "3. Obtain the segmentation of each image by predicted the cluster assigment of the pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_color_superpixel_response(image, segments_slic):    \n",
    "    \"\"\"\n",
    "    For each superpixel, obtain the mean rgb value.\n",
    "    :param image.\n",
    "    :param segments_slic. The result obtained by running the SLIC algorith.\n",
    "    :return. The mean rgb value for each superpixel in the image.\n",
    "    \"\"\"\n",
    "    number_superpixels = segments_slic.max()\n",
    "    superpixel_mean_color = np.zeros((number_superpixels, 3))\n",
    "    \n",
    "    # TODO:\n",
    "    return superpixel_mean_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_superpixel_segmetation_based_on_color(image, kmeans_model):\n",
    "    \"\"\"\n",
    "    1. For each image, obtain the superpixels. \n",
    "    2. For each superpixel, obtain the mean rgb value.\n",
    "    3. Cluster the resulting features using the K-means algorithm.\n",
    "    4. Get the segmentation map by labelling each superpixel with the corresponding cluster label.\n",
    "    \"\"\"\n",
    "    # TODO:\n",
    "    segments_slic = ...\n",
    "    \n",
    "    segmentation = np.zeros_like(segments_slic)\n",
    "     \n",
    "    return segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_images_with_superpixel_based_on_color(image_paths, num_clusters=5, method_name=\"superpixel_color\"):\n",
    "    \"\"\"\n",
    "    1. Get the superpixel for each image.\n",
    "    2. For each superpixel, obtain the mean of the rgb values (these are the features). \n",
    "    2. Cluster the resulting features using the K-means algorithm.\n",
    "    3. Obtain the segmentation of each image by predicted the cluster assigment of the pixels.\n",
    "    \"\"\"\n",
    "    def get_superpixels_features(images_paths_):\n",
    "        features_ = [] \n",
    "        for image_path in images_paths_:\n",
    "            image = cv.imread(image_path)\n",
    "            segments_slic = apply_slic(image)\n",
    "            superpixel_mean_response = get_mean_color_superpixel_response(image, segments_slic)\n",
    "            features_.extend(superpixel_mean_response.reshape(-1, 3))\n",
    "        return np.array(features_)\n",
    "    \n",
    "    features = get_superpixels_features(image_paths)\n",
    "    print(f'Our features size is {features.shape}')\n",
    "    \n",
    "    kmeans_model = apply_kmeans(features, num_clusters=num_clusters)\n",
    "    \n",
    "    for image_path in image_paths:\n",
    "        img = cv.imread(image_path)\n",
    "        segmentation = get_superpixel_segmetation_based_on_color(img, kmeans_model=kmeans_model)\n",
    "        colored_segmentation = label_to_rgb(segmentation)\n",
    "        # save the output\n",
    "        save_history(image_path, colored_segmentation, method_name)\n",
    "        show_images(image_1=img, name_1='img', image_2=colored_segmentation, name_2='segmentation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run segmentation with superpixels based on color\n",
    "image_paths = glob.glob(\"dataset/*_s.bmp\") \n",
    "segment_images_with_superpixel_based_on_color(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_segmentation.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_segmentation_history():\n",
    "    \"\"\"\n",
    "    Display all the segmatation obtained in this lab.\n",
    "    \"\"\"\n",
    "    global history_segmentation\n",
    "    image_paths = list(history_segmentation.keys())\n",
    "    num_rows = len(image_paths)\n",
    "    num_cols = len(history_segmentation[image_paths[0]].keys()) + 2\n",
    "    \n",
    "    plt.figure(figsize=(50, 50))  \n",
    "                \n",
    "    for idx_row, image_path in enumerate(image_paths):\n",
    "        image = cv.imread(image_path) \n",
    "        gt_path = image_path.replace(\".bmp\", \"_HQGT.bmp\")\n",
    "        gt = cv.imread(gt_path)\n",
    "        \n",
    "        # plot \n",
    "        plt.subplot(num_rows, num_cols, idx_row * num_cols + 1)\n",
    "        plt.axis('off')                  \n",
    "        plt.imshow(image[:, :, [2, 1, 0]])\n",
    "        plt.title('image')\n",
    "        \n",
    "        plt.subplot(num_rows, num_cols, idx_row * num_cols + 2)   \n",
    "        plt.axis('off') \n",
    "        plt.imshow(gt[:, :, [2, 1, 0]])\n",
    "        plt.title('gt')\n",
    "        \n",
    "        segmentation_types = list(history_segmentation[image_path].keys())\n",
    "        for idx_seg, segmentation_type in enumerate(segmentation_types):\n",
    "            segmentation = history_segmentation[image_path][segmentation_type]\n",
    "            plt.subplot(num_rows, num_cols, idx_row * num_cols + 3 + idx_seg) \n",
    "            plt.axis('off') \n",
    "            plt.title(segmentation_type)\n",
    "            plt.imshow(segmentation[:, :, [2, 1, 0]])\n",
    "    plt.savefig('segmentation_history.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_segmentation_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRABCUT - interactive foreground extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.docs.opencv.org/master/d8/d83/tutorial_py_grabcut.html\n",
    "def run_grabcut(img):\n",
    "    mask = np.zeros(img.shape[:2], np.uint8)\n",
    "    bgdModel = np.zeros((1,65), np.float64)\n",
    "    fgdModel = np.zeros((1,65), np.float64)\n",
    "    rect = cv.selectROI(img)\n",
    "    cv.destroyAllWindows()\n",
    "    cv.grabCut(img, mask, rect, bgdModel, fgdModel, 5, cv.GC_INIT_WITH_RECT)\n",
    "    mask2 = np.where((mask == 2)|(mask == 0),0,1).astype('uint8')\n",
    "    img = img * mask2[:, :, np.newaxis]\n",
    "    return img, mask\n",
    "    \n",
    "img = cv.imread('dataset/2_21_s.bmp')\n",
    "img_grabcut, mask = run_grabcut(img)\n",
    "show_images(image_1=img_grabcut, name_1='img_grabcut') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('dataset/14_18_s.bmp')\n",
    "img_grabcut, mask = run_grabcut(img)\n",
    "show_images(image_1=img_grabcut, name_1='img_grabcut') \n",
    "# newmask is the mask image I manually labelled\n",
    "newmask = cv.imread('14_18_s_paint.bmp',0)\n",
    "# wherever it is marked white (sure foreground), change mask=1\n",
    "# wherever it is marked black (sure background), change mask=0\n",
    "mask[newmask == 0] = 0\n",
    "mask[newmask == 255] = 1\n",
    "bgdModel = np.zeros((1,65),np.float64)\n",
    "fgdModel = np.zeros((1,65),np.float64)\n",
    "mask, bgdModel, fgdModel = cv.grabCut(img, mask, None, bgdModel, fgdModel, 5, cv.GC_INIT_WITH_MASK)\n",
    "mask = np.where((mask == 2)|(mask == 0), 0, 1).astype('uint8')\n",
    "img_refined = img * mask[:, :, np.newaxis] \n",
    "show_images(image_1=img_refined, name_1='img_grabcut_refined') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
