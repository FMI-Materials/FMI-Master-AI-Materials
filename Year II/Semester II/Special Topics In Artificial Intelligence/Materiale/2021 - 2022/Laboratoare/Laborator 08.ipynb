{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow Error Fix\n",
    "import tensorflow\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import gym\n",
    "env = gym.make('SpaceInvaders-v0')\n",
    "env.reset()\n",
    "for _ in range(1000):\n",
    "    env.step(env.action_space.sample())\n",
    "    env.render('human')\n",
    "env.close()  # https://github.com/openai/gym/issues/893"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.pyplot._IonContext at 0x1b68b614520>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import cv2\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "import tensorflow.keras as tf\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Wrapper Class for the Gym Pong Environment\n",
    "class Pong:\n",
    "    def __init__(self):\n",
    "        self.env = gym.make(\"PongNoFrameskip-v4\")\n",
    "        self.ACTION_SPACE = [0, 2, 3]\n",
    "        self.env.reset()\n",
    "        self.SKIP_FRAMES = 8\n",
    "        self.NEUTRAL_ACTION = 0\n",
    "        self.FIRE_ACTION = 1\n",
    "        self.framecount = 0\n",
    "\n",
    "    def reset(self):\n",
    "        self.env.reset()\n",
    "        o, _, _, _ = self.env.step(self.FIRE_ACTION)\n",
    "        sum = 0\n",
    "        while sum < 70:\n",
    "            o, _, _, _ = self.env.step(self.NEUTRAL_ACTION)\n",
    "            o = self.prep_o(o)\n",
    "            sum = np.sum(o)\n",
    "        self.framecount = 0\n",
    "        return o\n",
    "\n",
    "    def neutral_step(self):\n",
    "        return self.step(self.NEUTRAL_ACTION)\n",
    "\n",
    "    def step(self, action):\n",
    "        rf = 0\n",
    "        self.framecount += 1\n",
    "        done = False\n",
    "        for _ in range(self.SKIP_FRAMES):\n",
    "            o, r, d = self.step_raw(self.ACTION_SPACE[action])\n",
    "            if not r == 0:\n",
    "                rf = r\n",
    "                done = True\n",
    "        return self.prep_o(o), rf, done\n",
    "\n",
    "    def step_raw(self, action):\n",
    "        o, r, d, _ = self.env.step(action)\n",
    "        return o, r, d\n",
    "\n",
    "    def o_imshow(self, o):\n",
    "        o = o * 255.0\n",
    "        o = o.astype(np.uint8)\n",
    "        cv2.imshow('o', o)\n",
    "        cv2.waitKey(20)\n",
    "\n",
    "    def prep_o(self, o):\n",
    "        o = o[35:195, :]\n",
    "        o = cv2.cvtColor(o, cv2.COLOR_RGB2GRAY)\n",
    "        ret, o = cv2.threshold(o, 100, 255, cv2.THRESH_BINARY)\n",
    "        o = cv2.resize(o, (80, 80))\n",
    "        o = o.astype(np.float64).reshape((80, 80, 1))\n",
    "        o = o / 255.0\n",
    "        return o\n",
    "\n",
    "    def render(self):\n",
    "        self.env.render()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "#RL Agent Class\n",
    "class Agent:\n",
    "    def __init__(self):\n",
    "        self.N_FRAMES = 4\n",
    "        self.framebuffer = deque(maxlen=self.N_FRAMES)\n",
    "        self.pong = Pong()\n",
    "        self.pong.reset()\n",
    "        self.EXPERIENCE_SIZE = 8192\n",
    "        self.experience = deque(maxlen=self.EXPERIENCE_SIZE)\n",
    "        self.stepcount = 0\n",
    "        self.LEARNING_RATE = 0.0001\n",
    "        self.make_models()\n",
    "        self.DISCOUNT = 0.95\n",
    "        self.EPSILON_MAX = 1.0\n",
    "        self.epsilon = self.EPSILON_MAX\n",
    "        self.EPSILON_MIN = 0.02\n",
    "        self.EPSILON_DECAY_STEPS = 10000\n",
    "        self.BATCH_SIZE = 32\n",
    "        self.fit_epoch_count = 1\n",
    "        self.UPDATE_TARGET_EVERY = 1000\n",
    "\n",
    "    def update_epsilon(self):\n",
    "        self.stepcount += 1\n",
    "        self.epsilon = max(self.EPSILON_MAX - (self.stepcount * (self.EPSILON_MAX / self.EPSILON_DECAY_STEPS)),\n",
    "                           self.EPSILON_MIN)\n",
    "\n",
    "    def play(self, state):\n",
    "        if random.random() < self.epsilon:\n",
    "            retval = random.choice(range(len(self.pong.ACTION_SPACE)))\n",
    "        else:\n",
    "            retval = np.argmax(self.running_model.predict(np.asarray([state]))[0])\n",
    "        self.update_epsilon()\n",
    "        return retval\n",
    "\n",
    "    def play_random_game(self):\n",
    "        o = self.pong.reset()\n",
    "        for _ in range(self.N_FRAMES):\n",
    "            self.framebuffer.append(o)\n",
    "            o, _, _ = self.pong.neutral_step()\n",
    "        done = False\n",
    "        while not done:\n",
    "            old_state = self.make_state()\n",
    "            action = random.choice(range(len(self.pong.ACTION_SPACE)))\n",
    "            o_new, r, done = self.pong.step(action)\n",
    "            self.framebuffer.append(o_new)\n",
    "            new_state = self.make_state()\n",
    "            self.experience.append((old_state, action, r, new_state, done))\n",
    "\n",
    "    def make_state(self):\n",
    "        return np.concatenate(self.framebuffer, axis=-1)\n",
    "\n",
    "    def validate_experience(self):\n",
    "        old_state, action, reward, new_state, done = random.choice(self.experience)\n",
    "        fig, axs = plt.subplots(2, 4)\n",
    "        for i in range(2):\n",
    "            if i == 0:\n",
    "                state = old_state\n",
    "            else:\n",
    "                state = new_state\n",
    "            for j in range(self.N_FRAMES):\n",
    "                axs[i][j].imshow(state[:, :, j])\n",
    "        plt.show()\n",
    "\n",
    "    def play_and_learn(self, numgames):\n",
    "        game_lengths = []\n",
    "        epsilons = []\n",
    "        losses = []\n",
    "        rewards = []\n",
    "        fig, axs = plt.subplots(2, 2)\n",
    "        axs[0][0].set_title(\"Game Length\")\n",
    "        axs[0][1].set_title(\"Epsilon\")\n",
    "        axs[1][0].set_title(\"Ultimate Reward\")\n",
    "        axs[1][1].set_title(\"Mean DQN Loss\")\n",
    "        plt.subplots_adjust(hspace=0.8, wspace=0.3)\n",
    "        for ep in tqdm(range(numgames)):                \n",
    "            game_losses = []\n",
    "            o = self.pong.reset()\n",
    "            for _ in range(self.N_FRAMES):\n",
    "                self.framebuffer.append(o)\n",
    "                o, _, _ = self.pong.neutral_step()\n",
    "            done = False\n",
    "            while not done:\n",
    "                self.pong.render()\n",
    "                old_state = self.make_state()\n",
    "                action = self.play(old_state)\n",
    "                o_new, r, done = self.pong.step(action)\n",
    "                self.framebuffer.append(o_new)\n",
    "                new_state = self.make_state()\n",
    "                self.experience.append((old_state, action, r, new_state, done))\n",
    "                ls = self.experience_replay()[0]\n",
    "                game_losses.append(ls)\n",
    "            rewards.append(r)\n",
    "            losses.append(sum(game_losses) / len(game_losses))\n",
    "            game_lengths.append(self.pong.framecount)\n",
    "            epsilons.append(self.epsilon)\n",
    "            axs[0][0].plot(game_lengths)\n",
    "            axs[0][1].plot(epsilons)\n",
    "            axs[1][0].plot(rewards)\n",
    "            axs[1][1].plot(losses)\n",
    "            plt.show()\n",
    "            plt.pause(0.01)\n",
    "        return game_lengths\n",
    "\n",
    "    def process_batch(self, batch):\n",
    "        old_states = [x for x, _, _, _, _ in batch]\n",
    "        new_states = [x for _, _, _, x, _ in batch]\n",
    "        old_rewards = self.running_model.predict(np.asarray(old_states))\n",
    "        new_rewards = self.target_model.predict(np.asarray(new_states))\n",
    "        for i, (old_state, action, reward, new_state, done) in enumerate(batch):\n",
    "            add_q = 0\n",
    "            if not done:\n",
    "                add_q = self.DISCOUNT * np.amax(new_rewards[i])\n",
    "            q_value = reward + add_q\n",
    "            old_rewards[i][action] = q_value\n",
    "        return np.asarray(old_states), old_rewards\n",
    "\n",
    "    def experience_replay(self):\n",
    "        batch = random.choices(self.experience, k=32)\n",
    "        x, y = self.process_batch(batch)\n",
    "        hist = self.running_model.fit(x, y, verbose=False)\n",
    "        self.fit_epoch_count += 1\n",
    "        if self.stepcount % self.UPDATE_TARGET_EVERY == 0:\n",
    "            self.target_model.set_weights(self.running_model.get_weights().copy())\n",
    "        return hist.history['loss']\n",
    "\n",
    "    def make_models(self):\n",
    "        self.running_model = tf.Sequential()\n",
    "        self.target_model = tf.Sequential()\n",
    "        self.add_layers_to(self.running_model)\n",
    "        self.add_layers_to(self.target_model)\n",
    "        self.running_model.compile(optimizer=Adam(learning_rate=self.LEARNING_RATE), loss='mse')\n",
    "        self.running_model.summary()\n",
    "\n",
    "    def add_layers_to(self, model: tf.Sequential):\n",
    "        layerlist = [\n",
    "            Conv2D(32, 8, 4, use_bias=False, activation='relu', input_shape=(80, 80, self.N_FRAMES)),\n",
    "            Conv2D(16, 4, 2, use_bias=False, activation='relu'),\n",
    "            Conv2D(16, 3, 1, use_bias=False, activation='relu'),\n",
    "            Flatten(),\n",
    "            Dense(512, use_bias=False, activation='relu'),\n",
    "            Dense(len(self.pong.ACTION_SPACE), use_bias=False, activation='linear')\n",
    "        ]\n",
    "        [model.add(x) for x in layerlist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 19, 19, 32)        8192      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 8, 8, 16)          8192      \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 6, 6, 16)          2304      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 576)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               294912    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 1536      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 315,136\n",
      "Trainable params: 315,136\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 4 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 22/10000 [01:11<8:46:43,  3.17s/it] "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_45460/1371157105.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m#Begin Training\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0ma\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mAgent\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0ma\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mplay_and_learn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m10000\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_45460/3874621911.py\u001B[0m in \u001B[0;36mplay_and_learn\u001B[1;34m(self, numgames)\u001B[0m\n\u001B[0;32m     90\u001B[0m                 \u001B[0mnew_state\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmake_state\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     91\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexperience\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mold_state\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maction\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mr\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnew_state\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 92\u001B[1;33m                 \u001B[0mls\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexperience_replay\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     93\u001B[0m                 \u001B[0mgame_losses\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mls\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     94\u001B[0m             \u001B[0mrewards\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mr\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_45460/3874621911.py\u001B[0m in \u001B[0;36mexperience_replay\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    119\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mexperience_replay\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    120\u001B[0m         \u001B[0mbatch\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mrandom\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mchoices\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexperience\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mk\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m32\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 121\u001B[1;33m         \u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprocess_batch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    122\u001B[0m         \u001B[0mhist\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrunning_model\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    123\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit_epoch_count\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_45460/3874621911.py\u001B[0m in \u001B[0;36mprocess_batch\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    107\u001B[0m         \u001B[0mold_states\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mx\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mbatch\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    108\u001B[0m         \u001B[0mnew_states\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mx\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mbatch\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 109\u001B[1;33m         \u001B[0mold_rewards\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrunning_model\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masarray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mold_states\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    110\u001B[0m         \u001B[0mnew_rewards\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtarget_model\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masarray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnew_states\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    111\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mold_state\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maction\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreward\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnew_state\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdone\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\cipri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     62\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     63\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 64\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     65\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# pylint: disable=broad-except\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     66\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\cipri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mpredict\u001B[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1783\u001B[0m       \u001B[0mcallbacks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mon_predict_begin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1784\u001B[0m       \u001B[0mbatch_outputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1785\u001B[1;33m       \u001B[1;32mfor\u001B[0m \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0miterator\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0menumerate_epochs\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# Single epoch.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1786\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcatch_stop_iteration\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1787\u001B[0m           \u001B[1;32mfor\u001B[0m \u001B[0mstep\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msteps\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\cipri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001B[0m in \u001B[0;36menumerate_epochs\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1193\u001B[0m     \u001B[1;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1194\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_truncate_execution_to_epoch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1195\u001B[1;33m       \u001B[0mdata_iterator\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0miter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_dataset\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1196\u001B[0m       \u001B[1;32mfor\u001B[0m \u001B[0mepoch\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_initial_epoch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_epochs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1197\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_insufficient_data\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# Set by `catch_stop_iteration`.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\cipri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001B[0m in \u001B[0;36m__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    488\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mcontext\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexecuting_eagerly\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minside_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    489\u001B[0m       \u001B[1;32mwith\u001B[0m \u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolocate_with\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_variant_tensor\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 490\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0miterator_ops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mOwnedIterator\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    491\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    492\u001B[0m       raise RuntimeError(\"`tf.data.Dataset` only supports Python-style \"\n",
      "\u001B[1;32mc:\\users\\cipri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, dataset, components, element_spec)\u001B[0m\n\u001B[0;32m    724\u001B[0m             \u001B[1;34m\"When `dataset` is provided, `element_spec` and `components` must \"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    725\u001B[0m             \"not be specified.\")\n\u001B[1;32m--> 726\u001B[1;33m       \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_create_iterator\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    727\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    728\u001B[0m     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_get_next_call_count\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\cipri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001B[0m in \u001B[0;36m_create_iterator\u001B[1;34m(self, dataset)\u001B[0m\n\u001B[0;32m    749\u001B[0m               \u001B[0moutput_types\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_flat_output_types\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    750\u001B[0m               output_shapes=self._flat_output_shapes))\n\u001B[1;32m--> 751\u001B[1;33m       \u001B[0mgen_dataset_ops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmake_iterator\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mds_variant\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_iterator_resource\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    752\u001B[0m       \u001B[1;31m# Delete the resource when this object is deleted\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    753\u001B[0m       self._resource_deleter = IteratorResourceDeleter(\n",
      "\u001B[1;32mc:\\users\\cipri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\u001B[0m in \u001B[0;36mmake_iterator\u001B[1;34m(dataset, iterator, name)\u001B[0m\n\u001B[0;32m   3234\u001B[0m   \u001B[1;32mif\u001B[0m \u001B[0mtld\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_eager\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3235\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3236\u001B[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001B[0m\u001B[0;32m   3237\u001B[0m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001B[0;32m   3238\u001B[0m       \u001B[1;32mreturn\u001B[0m \u001B[0m_result\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "#Begin Training\n",
    "a = Agent()\n",
    "a.play_and_learn(10000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}